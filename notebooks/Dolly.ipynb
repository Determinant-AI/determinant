{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbvlIw0g06Og"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate>=0.12.0 transformers[torch]==4.25.1 \n",
        "!pip install -U \"ray[serve]\"  # installs Ray + dependencies for Ray Serve\n",
        "!pip install -U slack-bolt\n",
        "!pip install faiss-cpu\n",
        "!pip install atlassian-python-api\n",
        "!pip install numpy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "from fastapi import FastAPI, Request\n",
        "from ray import serve\n",
        "from slack_bolt.async_app import AsyncApp\n",
        "from slack_bolt.adapter.fastapi.async_handler import AsyncSlackRequestHandler\n",
        "from slack_bolt.adapter.starlette.handler import SlackRequestHandler\n",
        "import requests\n",
        "from slack_sdk.signature import SignatureVerifier\n",
        "\n",
        "import logging\n",
        "# Configure the logger.\n"
      ],
      "metadata": {
        "id": "9i2ye_Idw8Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from atlassian import Confluence\n",
        "import os\n",
        "\n",
        "# Set up Confluence API connection\n",
        "confluence = Confluence(\n",
        "url='https://advendio.atlassian.net',\n",
        ")\n",
        "confluence\n",
        "space_key = \"SO\"\n",
        "pages = confluence.get_all_pages_from_space(space_key)\n",
        "pages\n",
        "# Create a directory to store the downloaded pages\n",
        "if not os.path.exists('advendio_pages'):\n",
        "    os.makedirs('advendio_pages')\n",
        "# Download each page\n",
        "for page in pages:\n",
        "    page_id = page['id']\n",
        "    page_title = page['title']\n",
        "    page_filename = page_title.replace(' ', '_') + '.html'\n",
        "    page_content = confluence.get_page_by_id(page_id, expand='body.storage')['body']['storage']['value']\n",
        "    try:\n",
        "        with open('advendio_pages/' + page_filename, 'w') as f:\n",
        "            f.write(page_content)\n",
        "    except:\n",
        "        pass\n",
        "    print('Downloaded:', page_filename)\n"
      ],
      "metadata": {
        "id": "TanAqVes683S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls advendio_pages"
      ],
      "metadata": {
        "id": "jhy3Xdy-7Lpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from typing import List\n",
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
        "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import faiss\n",
        "# Load questions and contexts\n",
        "\n",
        "\n",
        "# make it integration with Slack Ingestor\n",
        "@serve.deployment()\n",
        "class DocumentVectorDB:\n",
        "    def __init__(self, question_encoder_model: str = \"facebook/dpr-question_encoder-single-nq-base\"):\n",
        "        self.token_limit = 512\n",
        "\n",
        "        self.documents = self.format_documents()\n",
        "        self.question_encoder = DPRQuestionEncoder.from_pretrained(\n",
        "            question_encoder_model)\n",
        "        self.question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\n",
        "            question_encoder_model)\n",
        "        self.context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "        self.context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "        count = self.index_documents(self.documents)\n",
        "        print(count)\n",
        "      \n",
        "    # def __call__(self, request: Request) -> Dict:\n",
        "    #     print(\"hellp\")\n",
        "    #     req_str = \"what is ads campaign?\"\n",
        "    #     msg = self.documents[self.query_documents(req_str)]\n",
        "    #     return {\"result\": msg}\n",
        "\n",
        "    def index_documents(self, documents: List[str]) -> int:\n",
        "        # Encode the documents\n",
        "        encoded_documents = self.context_tokenizer(self.documents, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.token_limit)\n",
        "        document_embeddings = self.context_encoder(**encoded_documents).pooler_output\n",
        "\n",
        "        document_embeddings = document_embeddings.detach().numpy()\n",
        "        document_embeddings=np.ascontiguousarray(document_embeddings)\n",
        "        # Create Faiss Index\n",
        "        vector_dimension = document_embeddings.shape[1]\n",
        "        # print(vector_dimension)\n",
        "        self.index = faiss.IndexFlatL2(vector_dimension)\n",
        "        faiss.normalize_L2(document_embeddings)\n",
        "        self.index.add(document_embeddings)\n",
        "        return self.index.ntotal\n",
        "\n",
        "    def insert_documents(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        store some whre\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def encode_questions(self, query: str) -> List[torch.Tensor]:\n",
        "        encoded_query = self.question_tokenizer(query, return_tensors=\"pt\")\n",
        "        query_embedding = self.question_encoder(\n",
        "            **encoded_query).pooler_output.detach().numpy()\n",
        "        query_embedding = np.ascontiguousarray(query_embedding)\n",
        "        return query_embedding\n",
        "\n",
        "    def query_documents(self, query: str) -> str:\n",
        "        # Encode the query\n",
        "        query_embedding = self.encode_questions(query)\n",
        "        _, idx = self.index.search(query_embedding, 4)\n",
        "        return self.documents[idx[0][0]]\n",
        "\n",
        "    def format_documents(self):\n",
        "        documents = []\n",
        "        for filename in os.listdir('advendio_pages'):\n",
        "            f = os.path.join('advendio_pages', filename)\n",
        "            with open(f, 'r', encoding='utf-8') as file:\n",
        "                html_content = file.read()\n",
        "                soup = BeautifulSoup(html_content, \"lxml\")\n",
        "\n",
        "                text_content = soup.get_text(separator=\" \", strip=True)\n",
        "                documents.append(text_content)\n",
        "        return documents\n",
        "\n",
        "@serve.deployment(route_prefix=\"/\")\n",
        "class ConversationBot:\n",
        "    def __init__(self, db: DocumentVectorDB, model: str = \"databricks/dolly-v2-12b\"):\n",
        "        self.model = model\n",
        "        self.db = db\n",
        "\n",
        "    async def prompt(self, input: str):\n",
        "        print('in prompt:')\n",
        "        context = await self.db.query_documents.remote(input)\n",
        "        print(\"context: {}\".format(context))\n",
        "        result = \"{input} \\n context: {}\\n\".format(context)\n",
        "        print(result)\n",
        "        return result\n",
        "\n",
        "    def generate_text(self, input_text: str) -> str:\n",
        "        generator = pipeline(model=self.model,\n",
        "                             torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n",
        "        print(\"here generated text\")\n",
        "        return generator(self.prompt(input_text))[0][\"generated_text\"]\n",
        "\n",
        "    async def __call__(self, http_request: Request) -> str:\n",
        "        input_text: str = await http_request.json()\n",
        "        return self.generate_text(input_text)\n",
        "\n",
        "# 2: Deploy the model.\n",
        "serve.run(ConversationBot.bind(DocumentVectorDB.bind()))\n",
        "\n",
        "english_text = \"what is an ads event?\"\n",
        "# 3: Query the deployment and print the result.\n",
        "response = requests.post(\"http://127.0.0.1:8000/\", json=english_text)\n",
        "french_text = response.text\n",
        "\n",
        "print(french_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "dghaFzvuvhIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = DocumentVectorDB()\n",
        "db('what is ads campaign?')"
      ],
      "metadata": {
        "id": "AKaySQIt7hcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dolly_chat_bot = ConversationBot(\"databricks/dolly-v2-12b\")\n",
        "# slack_agent = SlackAgent(dolly_chat_bot)\n",
        "\n",
        "# # TODO: setup the token and secrets\n",
        "\n",
        "# memory_buffer = RedisManager()\n",
        "# dolly_chat_bot.bind(memory_buffer)\n",
        "# slack_agent.bind(dolly_chat_bot)"
      ],
      "metadata": {
        "id": "VjEfmYD17gTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-mjE_V1A1CQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_text(\"\"\"\n",
        "Imagine a person John Lin is a pharmacy shopkeeper at the Willow Market and Pharmacy who loves to help people. He is always looking for ways to make the process of getting medication easier for his customers; John Lin is living with his wife, Mei Lin, who is a college professor, and son, Eddy Lin, who is a student studying music theory; John Lin loves his family very much; John Lin has known the old couple next-door, Sam Moore and Jennifer Moore, for a few years; John Lin thinks Sam Moore is a kind and nice man; John Lin knows his neighbor, Yuriko Yamamoto, well; John Lin knows of his neighbors, Tamara Taylor and Carmen Ortiz, but has not met them before; John Lin and Tom Moreno are colleagues at The Willows Market and Pharmacy; John Lin and Tom Moreno are friends and like to discuss local politics together; John Lin knows the Moreno family somewhat well — the husband Tom Moreno and the wife Jane Moreno.\n",
        "\n",
        "Generate conversation between John Lin and his wife in the morning:\n",
        "\"\"\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "WKCIKJNq1FHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Imagine a person John Lin is a pharmacy shopkeeper at the Willow Market and Pharmacy who loves to help people. He is always looking for ways to make the process of getting medication easier for his customers; John Lin is living with his wife, Mei Lin, who is a college professor, and son, Eddy Lin, who is a student studying music theory; John Lin loves his family very much; John Lin has known the old couple next-door, Sam Moore and Jennifer Moore, for a few years; John Lin thinks Sam Moore is a kind and nice man; John Lin knows his neighbor, Yuriko Yamamoto, well; John Lin knows of his neighbors, Tamara Taylor and Carmen Ortiz, but has not met them before; John Lin and Tom Moreno are colleagues at The Willows Market and Pharmacy; John Lin and Tom Moreno are friends and like to discuss local politics together; John Lin knows the Moreno family somewhat well — the husband Tom Moreno and the wife Jane Moreno.\n",
        "\n",
        "Plan a day for John Lin\n",
        "\"\"\"\n",
        "output = generate_text(prompt)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "vyZTnasE1G_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UACh1AU02tTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Please label the sentiment towards the movie of the given movie review. The sentiment label should be \"positive\" or \"negative\". \n",
        "Text: i'll bet the video game is a lot more fun than the film. \n",
        "Sentiment:\n",
        "\n",
        "\"\"\"\n",
        "output = generate_text(prompt)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "_9cuAa3Z3s-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Only output the last one\n",
        "\n",
        "Definition: Determine the speaker of the dialogue, \"agent\" or \"customer\".\n",
        "Input: I have successfully booked your tickets.\n",
        "Ouput: agent\n",
        "\n",
        "Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\n",
        "Input: What's the oldest building in US?\n",
        "Ouput: Location\n",
        "\n",
        "Definition: Classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
        "Input: i'll bet the video game is a lot more fun than the film.\n",
        "Output:\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "output = generate_text(prompt)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "Ffl16zmlOFvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"\"\"I have three models, 1. visual transformer, 2. Text generation model\n",
        ",  if i encounter this input from user: what is in the image? followed by an image file which model should I use?\n",
        "\n",
        "output your prediction of yes or no for option 1 and 2\n",
        "\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "noj418QZFmig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "What are some kinds of embroidery stitches for writing letters?\t\"\"\"\n",
        "\n",
        "output = generate_text(prompt)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "MQJkwgTQTot0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "jrpNiDzjDtaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
        "predictions = [generate_text(\"how does digital ads work in general?\")]\n",
        "results = perplexity.compute(predictions=predictions, model_id='databricks/dolly-v2-12b')\n"
      ],
      "metadata": {
        "id": "Uko8cmMu7maZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "WUCc41rKDrZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h8nXW1_xEAxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}